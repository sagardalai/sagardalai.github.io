<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Sagar Dalai ‚Äì AI & Robotics for Environmental Monitoring</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description"
        content="Story-style portfolio of Sagar Dalai ‚Äì PhD researcher at the University of Limerick using UAVs, AI, multispectral and hyperspectral imaging for environmental monitoring.">
  <style>
    :root {
      --bg: #020617;
      --text: #f9fafb;
      --muted: #cbd5f5;
      --accent: #facc15;
      --accent-soft: rgba(250, 204, 21, 0.14);
      --border: #1f2937;
      --max-width: 880px;
      --radius-lg: 18px;
      --shadow: 0 18px 45px rgba(15, 23, 42, 0.85);
    }

    * { box-sizing: border-box; margin: 0; padding: 0; }

    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "SF Pro Text",
                   "Segoe UI", sans-serif;
      background: radial-gradient(circle at top, #0b1120 0, #020617 50%, #000 100%);
      color: var(--text);
      line-height: 1.7;
    }

    main {
      max-width: var(--max-width);
      margin: 0 auto;
      padding: 32px 16px 72px;
    }

    a {
      color: inherit;
      text-decoration: none;
    }

    /* Intro / hero */

    header {
      margin-bottom: 40px;
    }

    .top-label {
      font-size: 12px;
      letter-spacing: 0.2em;
      text-transform: uppercase;
      color: var(--muted);
      display: inline-flex;
      align-items: center;
      gap: 8px;
      opacity: 0.9;
    }

    .top-dot {
      width: 8px;
      height: 8px;
      border-radius: 999px;
      background: var(--accent);
      box-shadow: 0 0 18px rgba(250, 204, 21, 0.9);
    }

    .hero-title {
      margin-top: 20px;
      font-size: clamp(2.4rem, 5vw, 3.2rem);
      line-height: 1.1;
      font-weight: 700;
      max-width: 780px;
    }

    .hero-title span {
      background: linear-gradient(to right, #facc15, #a3e635);
      -webkit-background-clip: text;
      background-clip: text;
      color: transparent;
    }

    .hero-subtitle {
      margin-top: 16px;
      max-width: 720px;
      font-size: 15px;
      color: var(--muted);
    }

    .hero-meta {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      margin-top: 20px;
      font-size: 13px;
    }

    .hero-chip {
      padding: 6px 12px;
      border-radius: 999px;
      border: 1px solid var(--border);
      background: rgba(15, 23, 42, 0.95);
      color: var(--muted);
      display: inline-flex;
      align-items: center;
      gap: 8px;
    }

    .hero-chip-dot {
      width: 7px;
      height: 7px;
      border-radius: 999px;
      background: #4ade80;
      box-shadow: 0 0 14px rgba(74, 222, 128, 0.9);
    }

    .hero-links {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      margin-top: 20px;
      font-size: 13px;
    }

    .hero-link {
      padding: 8px 14px;
      border-radius: 999px;
      border: 1px solid var(--border);
      background: rgba(15, 23, 42, 0.96);
      color: var(--muted);
      display: inline-flex;
      align-items: center;
      gap: 8px;
      cursor: pointer;
      transition: background 0.18s ease, transform 0.18s ease,
                  box-shadow 0.18s ease, border-color 0.18s ease;
    }

    .hero-link:hover {
      background: rgba(15, 23, 42, 1);
      transform: translateY(-1px);
      box-shadow: var(--shadow);
      border-color: rgba(148, 163, 184, 0.8);
      color: #e5e7eb;
    }

    /* Generic story blocks */

    section {
      margin-top: 40px;
    }

    h2 {
      font-size: 24px;
      font-weight: 700;
      margin-bottom: 10px;
      max-width: 760px;
    }

    h2 span {
      background: linear-gradient(to right, #facc15, #a855f7);
      -webkit-background-clip: text;
      background-clip: text;
      color: transparent;
    }

    h3 {
      font-size: 20px;
      font-weight: 700;
      margin: 24px 0 6px;
      max-width: 760px;
    }

    p {
      font-size: 15px;
      color: var(--muted);
      max-width: 780px;
    }

    p + p {
      margin-top: 8px;
    }

    .analogy {
      font-size: 16px;
      font-style: italic;
      margin: 16px 0 4px;
      max-width: 760px;
    }

    .image-row {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
      gap: 12px;
      margin: 18px 0;
    }

    .image-placeholder {
      border-radius: var(--radius-lg);
      border: 1px dashed rgba(148, 163, 184, 0.6);
      background: radial-gradient(circle at top left,
                  var(--accent-soft), rgba(15, 23, 42, 0.95));
      min-height: 150px;
      font-size: 12px;
      color: var(--muted);
      display: flex;
      align-items: center;
      justify-content: center;
      text-align: center;
      padding: 12px;
    }

    .highlight {
      margin-top: 18px;
      padding: 14px 16px;
      border-radius: var(--radius-lg);
      border: 1px solid rgba(148, 163, 184, 0.7);
      background: rgba(15, 23, 42, 0.98);
      font-size: 14px;
      color: var(--muted);
      max-width: 780px;
    }

    .highlight strong {
      color: var(--text);
    }

    /* Numbered + reason blocks */

    .numbers {
      font-size: 40px;
      font-weight: 800;
      margin: 16px 0 6px;
      color: var(--accent);
    }

    .reason-card {
      margin-top: 10px;
      padding: 14px 16px;
      border-radius: var(--radius-lg);
      border: 1px solid var(--border);
      background: rgba(15, 23, 42, 0.96);
      box-shadow: 0 10px 30px rgba(15, 23, 42, 0.9);
      max-width: 780px;
    }

    .reason-title {
      font-size: 16px;
      font-weight: 600;
      margin-bottom: 4px;
    }

    .reason-body {
      font-size: 14px;
      color: var(--muted);
    }

    /* Projects / cards */

    .project-card {
      margin-top: 18px;
      padding: 14px 16px;
      border-radius: var(--radius-lg);
      border: 1px solid var(--border);
      background: rgba(15, 23, 42, 0.96);
      box-shadow: 0 10px 28px rgba(15, 23, 42, 0.85);
      max-width: 780px;
    }

    .project-tagline {
      font-size: 11px;
      letter-spacing: 0.18em;
      text-transform: uppercase;
      color: var(--muted);
      opacity: 0.9;
      margin-bottom: 6px;
    }

    .project-title-row {
      display: flex;
      align-items: baseline;
      justify-content: space-between;
      gap: 12px;
    }

    .project-title {
      font-size: 16px;
      font-weight: 600;
    }

    .project-year {
      font-size: 12px;
      color: var(--muted);
      white-space: nowrap;
    }

    .project-body {
      margin-top: 6px;
      font-size: 14px;
      color: var(--muted);
    }

    .project-tags {
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
      margin-top: 8px;
      font-size: 11px;
    }

    .project-tag {
      padding: 3px 8px;
      border-radius: 999px;
      border: 1px solid var(--border);
      background: rgba(15, 23, 42, 0.98);
      color: var(--muted);
    }

    .project-link {
      display: inline-flex;
      align-items: center;
      gap: 6px;
      margin-top: 8px;
      font-size: 12px;
      padding: 4px 8px;
      border-radius: 999px;
      border: 1px solid rgba(148, 163, 184, 0.7);
      background: rgba(15, 23, 42, 0.96);
      cursor: pointer;
    }

    /* Timeline */

    .timeline {
      margin-top: 18px;
      border-radius: var(--radius-lg);
      border: 1px solid var(--border);
      background: rgba(15, 23, 42, 0.96);
      padding: 14px 16px;
      max-width: 780px;
    }

    .timeline-item {
      padding: 8px 0;
    }

    .timeline-item + .timeline-item {
      border-top: 1px solid rgba(31, 41, 55, 0.9);
    }

    .timeline-main {
      display: flex;
      justify-content: space-between;
      gap: 10px;
    }

    .timeline-role {
      font-size: 14px;
      font-weight: 600;
    }

    .timeline-date {
      font-size: 12px;
      color: var(--muted);
      white-space: nowrap;
    }

    .timeline-org {
      font-size: 13px;
      color: var(--muted);
      margin-top: 2px;
    }

    .timeline-desc {
      font-size: 13px;
      color: var(--muted);
      margin-top: 4px;
    }

    /* References */

    .references {
      margin-top: 24px;
      font-size: 12px;
      color: var(--muted);
      max-width: 780px;
    }

    .references h3 {
      font-size: 16px;
      margin-bottom: 8px;
    }

    .references ul {
      list-style: disc;
      padding-left: 18px;
    }

    .references li {
      margin-bottom: 4px;
    }

    /* CTA */

    .cta {
      margin-top: 32px;
      padding: 16px 16px 14px;
      border-radius: var(--radius-lg);
      border: 1px solid rgba(234, 179, 8, 0.7);
      background: radial-gradient(circle at top left,
                  var(--accent-soft), rgba(15, 23, 42, 0.96));
      box-shadow: var(--shadow);
      font-size: 14px;
      color: var(--muted);
      max-width: 780px;
    }

    .cta strong { color: var(--text); }

    .cta-actions {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      margin-top: 14px;
    }

    .cta-btn {
      padding: 8px 14px;
      border-radius: 999px;
      border: 1px solid rgba(234, 179, 8, 0.8);
      background: rgba(15, 23, 42, 1);
      font-size: 13px;
      display: inline-flex;
      align-items: center;
      gap: 6px;
      cursor: pointer;
      color: var(--text);
    }

    .cta-btn.secondary {
      border-color: var(--border);
      background: rgba(15, 23, 42, 0.96);
      color: var(--muted);
    }

    .cta-btn:hover {
      box-shadow: var(--shadow);
      transform: translateY(-1px);
    }

    footer {
      margin-top: 40px;
      padding-top: 16px;
      border-top: 1px solid var(--border);
      font-size: 11px;
      color: var(--muted);
      display: flex;
      justify-content: space-between;
      gap: 8px;
      flex-wrap: wrap;
    }

    @media (max-width: 600px) {
      .hero-title {
        font-size: 2.2rem;
      }
      .timeline-main {
        flex-direction: column;
        align-items: flex-start;
      }
    }
  </style>
</head>
<body>
<main>

  <!-- HERO / INTRO -->
  <header>
    <div class="top-label">
      <span class="top-dot"></span>
      <span>AI &amp; Robotics for Environmental Monitoring</span>
    </div>

    <h1 class="hero-title">
      <span>Drones, AI and hyperspectral imaging</span> to understand and protect our waters.
    </h1>

    <p class="hero-subtitle">
      I‚Äôm <strong>Sagar Dalai</strong>, a PhD researcher at the University of Limerick, Ireland.
      I use UAVs, multispectral and hyperspectral sensors, and machine learning to monitor
      water quality, harmful algal blooms and coastal environments in a more autonomous,
      data-rich way.
    </p>

    <div class="hero-meta">
      <div class="hero-chip">
        <span class="hero-chip-dot"></span>
        <span>PhD ‚Äì University of Limerick</span>
      </div>
      <div class="hero-chip">
        üåä Focus: Irish coastal & inland waters
      </div>
      <div class="hero-chip">
        ü§ñ Robotics ¬∑ Remote sensing ¬∑ ML
      </div>
    </div>

    <div class="hero-links">
      <!-- TODO: put your real contact links here -->
      <a class="hero-link" href="mailto:YOUR_EMAIL@example.com">
        <span>‚úâÔ∏è</span><span>Email</span>
      </a>
      <a class="hero-link" href="https://github.com/YOUR_GITHUB" target="_blank" rel="noreferrer">
        <span>üêô</span><span>GitHub</span>
      </a>
      <a class="hero-link" href="https://www.linkedin.com/in/YOUR_LINKEDIN" target="_blank" rel="noreferrer">
        <span>üîó</span><span>LinkedIn</span>
      </a>
    </div>
  </header>

  <!-- PROBLEM SECTION -->
  <section>
    <h2><span>Environmental monitoring still misses a lot of what matters.</span></h2>

    <p>
      Monitoring water quality and coastal ecosystems is often slow, expensive and patchy.
      Boat campaigns and discrete sampling days can‚Äôt always follow fast processes like
      harmful algal blooms, changing turbidity, or rapid ecosystem changes along the coast.
    </p>
    <p>
      At the same time, we have access to UAVs, compact multispectral and hyperspectral cameras,
      and enough compute to process data almost in real time. The problem is not the hardware:
      it‚Äôs turning that hardware into <strong>reliable, automated monitoring systems</strong>
      that scientists and practitioners can trust.
    </p>

    <p class="analogy">
      Het is alsof je het weer van een jaar probeert te begrijpen met slechts tien foto‚Äôs
      van de lucht.
    </p>

    <p>
      We need dense observations in space and time, not isolated snapshots.
    </p>

    <div class="image-row">
      <div class="image-placeholder">
        Placeholder ‚Äì UAV survey over Irish waters<br>
        (replace with your own orthomosaic / UAV photo)
      </div>
      <div class="image-placeholder">
        Placeholder ‚Äì false-colour multispectral / hyperspectral image<br>
        (replace with real data visualisation)
      </div>
    </div>

    <div class="highlight">
      <strong>My research goal:</strong> build end-to-end UAV-based pipelines that turn
      raw spectral data into robust maps and indicators of water quality and ecosystem state,
      in a way that is <strong>repeatable, scalable and interpretable</strong>.
    </div>
  </section>

  <!-- CONSEQUENCES -->
  <section>
    <h2>When monitoring is fragmented, <span>we miss important changes.</span></h2>

    <p>
      If we rely only on occasional field campaigns or coarse satellite products, we risk:
    </p>

    <p>
      ‚Ä¢ Detecting harmful algal blooms too late, when they already impact aquaculture
      or tourism.<br>
      ‚Ä¢ Underestimating small-scale variability near coasts, estuaries and rivers.<br>
      ‚Ä¢ Lacking high-quality ground truth to validate satellite missions and models.
    </p>

    <p>
      My work combines <strong>UAVs</strong>, <strong>spectral sensors</strong> and
      <strong>machine learning</strong> to fill this gap at local scales, and to support
      better use of satellite data at regional scales.
    </p>
  </section>

  <!-- PIPELINE / APPROACH -->
  <section>
    <h2><span>I work across the whole pipeline ‚Äì from raw data to maps and insights.</span></h2>

    <h3>1. Smart data collection with UAVs</h3>
    <p>
      I plan and execute UAV missions for water and coastal monitoring, using platforms
      like DJI Mavic 3 Multispectral and custom payload setups. This includes flight
      planning, radiometric calibration and integration with onboard compute when needed.
    </p>

    <div class="image-row">
      <div class="image-placeholder">
        UAV mission planning screenshot<br>
        (replace with QGIS / mission planner image)
      </div>
      <div class="image-placeholder">
        DJI multispectral / Agrowing lens setup<br>
        (replace with your sensor photo)
      </div>
    </div>

    <h3>2. From images to spectral products</h3>
    <p>
      I use tools such as Agisoft Metashape, ENVI and custom Python pipelines to create
      orthomosaics, dense point clouds, and spectral cubes from UAV data. I work with:
    </p>
    <p>
      ‚Ä¢ Multispectral sensors (e.g. Agrowing Sextuple with Sony A7R).<br>
      ‚Ä¢ Hyperspectral sensors (e.g. Resonon Pika-L, VNIR range).<br>
      ‚Ä¢ Indices and spectral features tailored to water quality and vegetation.
    </p>

    <h3>3. Machine learning on multispectral & hyperspectral data</h3>
    <p>
      I explore and develop models for hyperspectral image classification, including:
    </p>
    <p>
      ‚Ä¢ Lightweight Vision Transformers with spectral attention.<br>
      ‚Ä¢ Capsule-based architectures (<strong>TinyCapsViT</strong>) for spectral‚Äìspatial
        relationships.<br>
      ‚Ä¢ Active learning / RL-based data selection to reduce labelling effort.
    </p>

    <h3>4. Autonomous UAV behaviour & control</h3>
    <p>
      Reliable monitoring requires stable, predictable UAV trajectories. I work on
      <strong>discrete-time PID control with online gain adaptation</strong> for smooth
      path following, validated on platforms like the DJI M100 with Intel RealSense
      D435i and T265 for perception.
    </p>
  </section>

  <!-- ‚ÄúTHIS NEW WAY WORKS‚Äù ‚Äì PROJECT CARDS LIKE THE 1/2/3/4 PART -->
  <section>
    <h2>This approach is already leading to <span>concrete frameworks and ideas.</span></h2>

    <div class="numbers">1</div>
    <div class="reason-card">
      <div class="reason-title">Autonomous mapping of Irish waters</div>
      <div class="reason-body">
        A framework to fuse multispectral, hyperspectral and satellite data for
        mapping Irish waters, with explicit cloud and water-vapour removal and the
        aim of producing clean, reusable time series for water quality and HAB studies.
      </div>
    </div>

    <div class="project-card">
      <div class="project-tagline">Coastal &amp; water quality monitoring</div>
      <div class="project-title-row">
        <div class="project-title">Autonomous mapping of Irish coastal waters</div>
        <div class="project-year">Ongoing</div>
      </div>
      <div class="project-body">
        Building an autonomous pipeline: from UAV raw data and satellite imagery
        to cloud-free, atmosphere-corrected products and classification maps useful
        for ecologists and decision-makers.
      </div>
      <div class="project-tags">
        <span class="project-tag">UAV</span>
        <span class="project-tag">Hyperspectral</span>
        <span class="project-tag">Water quality</span>
      </div>
    </div>

    <div class="numbers">2</div>
    <div class="reason-card">
      <div class="reason-title">Tiny models for rich spectral data</div>
      <div class="reason-body">
        With <strong>TinyCapsViT</strong> and related architectures I explore how to
        keep models small and efficient while still capturing the high-dimensional,
        highly correlated nature of hyperspectral data.
      </div>
    </div>

    <div class="project-card">
      <div class="project-tagline">Hyperspectral image analysis</div>
      <div class="project-title-row">
        <div class="project-title">TinyCapsViT for HSI classification</div>
        <div class="project-year">Research</div>
      </div>
      <div class="project-body">
        A compact Capsule-Vision Transformer tailored to hyperspectral image classification,
        targeting better trade-offs between accuracy, parameters and generalisation to
        new environments.
      </div>
      <div class="project-tags">
        <span class="project-tag">Vision Transformer</span>
        <span class="project-tag">Capsule networks</span>
        <span class="project-tag">HSI</span>
      </div>
    </div>

    <div class="numbers">3</div>
    <div class="reason-card">
      <div class="reason-title">Stable control for data-centric missions</div>
      <div class="reason-body">
        Smooth, predictable UAV motion is crucial for high-quality spectral and
        point-cloud products. My work on discrete-time PID with online gain adaptation
        improves tracking performance in real flights.
      </div>
    </div>

    <div class="project-card">
      <div class="project-tagline">UAV control &amp; autonomy</div>
      <div class="project-title-row">
        <div class="project-title">
          Discrete-time PID control with online gain adaptation
        </div>
        <div class="project-year">Conference work</div>
      </div>
      <div class="project-body">
        A controller tested on a DJI M100 platform with RealSense sensors, aiming
        for stable path-following in the presence of disturbances, for environmental
        surveying missions.
      </div>
      <div class="project-tags">
        <span class="project-tag">UAV control</span>
        <span class="project-tag">Path following</span>
        <span class="project-tag">Embedded</span>
      </div>
    </div>

    <div class="numbers">4</div>
    <div class="reason-card">
      <div class="reason-title">Ideas for multi-drone systems in complex terrain</div>
      <div class="reason-body">
        I‚Äôm exploring swarm-drone concepts for forest search &amp; rescue, using
        LiDAR, thermal cameras and SLAM to plan paths and coordinate between drones
        in dense, cluttered environments.
      </div>
    </div>

    <div class="project-card">
      <div class="project-tagline">Multi-robot systems</div>
      <div class="project-title-row">
        <div class="project-title">
          Swarm drone framework for forest search &amp; rescue
        </div>
        <div class="project-year">Proposal</div>
      </div>
      <div class="project-body">
        Concept for a DJI M300-based swarm using LiDAR, thermal imaging and
        centralised coordination, focusing on search strategies, path planning
        and robust communication in forest environments.
      </div>
      <div class="project-tags">
        <span class="project-tag">Swarm drones</span>
        <span class="project-tag">SLAM</span>
        <span class="project-tag">Search &amp; rescue</span>
      </div>
    </div>
  </section>

  <!-- PATH / TIMELINE -->
  <section>
    <h2><span>How I got here.</span></h2>

    <div class="timeline">
      <div class="timeline-item">
        <div class="timeline-main">
          <div class="timeline-role">
            PhD Researcher ‚Äì AI &amp; Robotics for Environmental Monitoring
          </div>
          <div class="timeline-date">
            University of Limerick ¬∑ Ireland
          </div>
        </div>
        <div class="timeline-org">
          Combining UAVs, spectral imaging, machine learning and control to
          build autonomous environmental monitoring frameworks.
        </div>
        <div class="timeline-desc">
          Focus on Irish waters, harmful algal blooms, water-quality mapping and
          data fusion between UAV and satellite observations.
        </div>
      </div>

      <div class="timeline-item">
        <div class="timeline-main">
          <div class="timeline-role">
            B.Tech ‚Äì First batch
          </div>
          <div class="timeline-date">
            2008 ‚Äì 2012
          </div>
        </div>
        <div class="timeline-org">
          Vignan Institute of Technology and Management
        </div>
        <div class="timeline-desc">
          Studied engineering as part of the institute‚Äôs first batch. An early
          struggle with C programming led to extra classes ‚Äî and eventually to a
          strong foundation in coding and problem-solving.
        </div>
      </div>
    </div>
  </section>

  <!-- REFERENCES / RESOURCES (OPTIONAL, LIKE THE ORIGINAL PAGE) -->
  <section class="references">
    <h3>Selected themes &amp; references I draw on</h3>
    <ul>
      <li>Deep learning for hyperspectral and multispectral image analysis.</li>
      <li>UAV photogrammetry and radiometric calibration.</li>
      <li>Water quality and harmful algal bloom monitoring using remote sensing.</li>
      <li>Control and planning for autonomous UAVs and multi-robot systems.</li>
    </ul>
  </section>

  <!-- CTA -->
  <section>
    <div class="cta">
      <p>
        <strong>Do you work on aquatic environments, remote sensing or robotics?</strong>
        I‚Äôm interested in collaborations where UAVs, spectral imaging and AI can help
        answer real environmental questions ‚Äî from mapping mussel beds and oysters
        to tracking algal blooms and coastal change.
      </p>
      <p style="margin-top:8px;">
        If you‚Äôre curious about using these tools in your project, or want to
        discuss data, algorithms or practical UAV workflows, feel free to reach out.
      </p>

      <div class="cta-actions">
        <a class="cta-btn" href="mailto:YOUR_EMAIL@example.com">
          <span>‚úâÔ∏è</span><span>Get in touch</span>
        </a>
        <a class="cta-btn secondary" href="https://github.com/YOUR_GITHUB" target="_blank" rel="noreferrer">
          <span>üêô</span><span>See code &amp; experiments on GitHub</span>
        </a>
      </div>
    </div>
  </section>

  <footer>
    <div>&copy; <span id="year"></span> Sagar Dalai ‚Äì Built for GitHub Pages.</div>
    <div>Based in Ireland ¬∑ AI &amp; Robotics ¬∑ Environmental Monitoring</div>
  </footer>
</main>

<script>
  document.getElementById('year').textContent = new Date().getFullYear();
</script>
</body>
</html>
